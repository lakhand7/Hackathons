{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from boruta import BorutaPy\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from knnmv_master.impute import KNNMVImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Interm/train.csv')\n",
    "test = pd.read_csv('Interm/test.csv')\n",
    "\n",
    "# train.fillna('NaN', inplace=True)\n",
    "# test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = train.shape[0]\n",
    "combine = train.append(test, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed 'City_Type','Employer_Category'\n",
    "list_one_hot_features = ['City_Type','Employer_Category','Category2','Category3']\n",
    "target_cols = ['Target_1','Target_2']\n",
    "\n",
    "# One hot encoding\n",
    "for i in list_one_hot_features:\n",
    "    temp_one_hot = pd.get_dummies(combine[[i]], columns=[i])\n",
    "    combine = combine.join(temp_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combine.iloc[0:train_index].reset_index(drop=True)\n",
    "test = combine.iloc[train_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for camp type 1 and 2 (Favorable Outcome: Getting a health score)\n",
    "** HS: Health Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHS = train[(train['Category1'] == 'First') | (train['Category1'] == 'Second')].reset_index(drop=True)\n",
    "\n",
    "testHS = test[(test['Category1'] == 'First') | (test['Category1'] == 'Second')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainHS[set(trainHS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                + list_one_hot_features + target_cols))]\n",
    "\n",
    "y = trainHS['Target_1']\n",
    "\n",
    "tempHS = testHS[['Patient_ID','Health_Camp_ID']]\n",
    "testHS = testHS[set(testHS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                                  + list_one_hot_features + target_cols))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=True) # Shuffle = True\n",
    "\n",
    "train_X = train_X.reset_index(drop=True); train_y = train_y.reset_index(drop=True);\n",
    "test_X = test_X.reset_index(drop=True); test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakhan\\Desktop\\Wyng\\Demand Forecasting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%cd C:/Users/Lakhan/Desktop/Wyng/Demand Forecasting\n",
    "from FeatureSelectionPipe import FeatureSelector\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Constant Features\n",
      "['Var2', 'Employer_Category_Food', 'Employer_Category_Retail', 'Var3', 'Employer_Category_Technology', 'Category3_2', 'Category2_G', 'City_Type_A', 'City_Type_F', 'Employer_Category_Broadcasting', 'Employer_Category_Software Industry', 'Category2_C', 'Employer_Category_Consulting', 'Employer_Category_Telecom', 'Category3_1', 'Employer_Category_Real Estate', 'Var4', 'Employer_Category_Education', 'Category2_B', 'Employer_Category_Transport', 'Employer_Category_Others', 'Employer_Category_BFSI', 'Employer_Category_Manufacturing', 'City_Type_I', 'Employer_Category_Health']\n",
      "\n",
      "Removing Correlated Features\n",
      "[]\n",
      "\n",
      "Removing Multicorrelated Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lakhan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Interaction_to_Camp_Start_Date', 'Registration_to_Camp_End_Date']\n",
      "\n",
      "Done selecting features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['City_Type_C',\n",
       " 'Age',\n",
       " 'Education_Score',\n",
       " 'Category2_F',\n",
       " 'City_Type_E',\n",
       " 'Var1',\n",
       " 'City_Type_D',\n",
       " 'Twitter_Shared',\n",
       " 'Online_Follower',\n",
       " 'Income',\n",
       " 'Facebook_Shared',\n",
       " 'LinkedIn_Shared',\n",
       " 'City_Type_H',\n",
       " 'Interaction_to_Registration',\n",
       " 'Registration_to_Camp_Start_Date',\n",
       " 'Interaction_to_Camp_End_Date',\n",
       " 'Category2_E',\n",
       " 'City_Type_B',\n",
       " 'Category2_D',\n",
       " 'City_Type_NaN',\n",
       " 'Employer_Category_NaN',\n",
       " 'Category2_A',\n",
       " 'Var5',\n",
       " 'City_Type_G']"
      ]
     },
     "execution_count": 1406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define steps\n",
    "step1 = {'Constant Features': {'frac_constant_values': 0.95}}\n",
    "\n",
    "step2 = {'Correlated Features': {'correlation_threshold': 0.95}}\n",
    "\n",
    "step3 = {'Multicorrelated Features': {'acceptable_vif_threshold': 50}}\n",
    "\n",
    "# # For RFECV Features, DecisionTreeRegressor can also be used as an estimator\n",
    "# estimator = RandomForestClassifier(random_state = 42, n_estimators = 20) \n",
    "\n",
    "# step5 = {'RFECV Features': {'estimator': estimator,\n",
    "#                     'cv': TimeSeriesSplit(n_splits=3), \n",
    "#                     'step': 1,\n",
    "#                     'scoring': 'accuracy', \n",
    "#                     'verbose': 50}}\n",
    "\n",
    "steps = [step1, step2, step3]\n",
    "\n",
    "# Initialize FeatureSelector()\n",
    "fs = FeatureSelector()\n",
    "\n",
    "# Apply feature selection methods\n",
    "fs.fit(train_X, train_y, steps)\n",
    "\n",
    "fs.selected_features\n",
    "\n",
    "selected_features = list(set(fs.selected_features + fs.critical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_selected = fs.transform(train_X)\n",
    "test_X_selected = fs.transform(test_X)\n",
    "\n",
    "testHS = fs.transform(testHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 40659, 1.0: 11079})\n",
      "Resampled dataset shape Counter({0.0: 40659, 1.0: 40659})\n"
     ]
    }
   ],
   "source": [
    "# applying smote\n",
    "# sm = SMOTE(sampling_strategy='auto',random_state=42)\n",
    "sm = BorderlineSMOTE(sampling_strategy='auto',random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(train_X_selected, train_y)\n",
    "print('Original dataset shape %s' % Counter(train_y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# train_X_selected, train_y\n",
    "# X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score of the classifier on the train set was: 67.72169936792827\n",
      "The roc_auc_score of the classifier on the test set was: 67.20108665872793\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# estimator = CatBoostClassifier(verbose=False, boosting_type='Plain')\n",
    "\n",
    "params = {'colsample_bytree': 1, 'eta': 0.1, 'max_depth': 7, 'n_estimators': 100, \n",
    "                'objective': 'binary:logistic', 'subsample': 0.8,}\n",
    "\n",
    "# c = Counter(train_y)\n",
    "#  'scale_pos_weight': c[0]/c[1]\n",
    "estimator = xgb.XGBClassifier()\n",
    "\n",
    "# # XGBClassifier\n",
    "# # early_stopping_rounds: The number of rounds without improvements after which we should stop\n",
    "# param_grid = { 'objective': ['binary:logistic'],\n",
    "#               'max_depth': [5,6,7], # 'min_child_weight': [5,6,7,8],\n",
    "#               'subsample': [0.8,0.9,1], 'colsample_bytree': [0.8,0.9,1],\n",
    "# # eta parameter: https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20208\n",
    "#               'eta': [0.1], 'n_estimators': [25, 50, 100]\n",
    "#          }\n",
    "\n",
    "\n",
    "# # Initialize GridSearch object with 5-fold cross validation\n",
    "# # error_score = 0 silences any exceptions for incorrect param combinations\n",
    "# gscv = GridSearchCV(estimator, param_grid, cv = 3,  n_jobs= -1, verbose = 1, scoring = 'roc_auc', error_score=0)\n",
    "\n",
    "# # Fit gscv\n",
    "# gscv = gscv.fit(train_X_selected, train_y)\n",
    "\n",
    "# # Get best parameters and score\n",
    "# best_params = gscv.best_params_\n",
    "# best_score = gscv.best_score_\n",
    "        \n",
    "# # Update classifier parameters\n",
    "# estimator = estimator.set_params(**best_params)\n",
    "\n",
    "# Fit classifier\n",
    "estimator = estimator.fit(train_X_selected, train_y)\n",
    "\n",
    "# Make predictions\n",
    "train_y_pred = estimator.predict(train_X_selected)\n",
    "test_y_pred = estimator.predict(test_X_selected)\n",
    "\n",
    "# Measure performance\n",
    "roc_auc_score_train = roc_auc_score(train_y, train_y_pred)\n",
    "roc_auc_score_test = roc_auc_score(test_y, test_y_pred)\n",
    "\n",
    "# Message to user\n",
    "print(f'The roc_auc_score of the classifier on the train set was: {roc_auc_score_train*100}')\n",
    "print(f'The roc_auc_score of the classifier on the test set was: {roc_auc_score_test*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempHS['Outcome'] = np.round(estimator.predict_proba(testHS)[:,1], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for camp type 3 (Favorable Outcome: Visiting a stall)\n",
    "** VS: Visiting a stall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVS = train[train['Category1'] == 'Third'].reset_index(drop=True)\n",
    "testVS = test[test['Category1'] == 'Third'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainVS[set(trainVS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                + list_one_hot_features + target_cols))]\n",
    "\n",
    "y = trainVS['Target_2']\n",
    "\n",
    "tempVS = testVS[['Patient_ID','Health_Camp_ID']]\n",
    "testVS = testVS[set(testVS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                            + list_one_hot_features+ target_cols))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=True) # Shuffle = True\n",
    "\n",
    "train_X = train_X.reset_index(drop=True); train_y = train_y.reset_index(drop=True);\n",
    "test_X = test_X.reset_index(drop=True); test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakhan\\Desktop\\Wyng\\Demand Forecasting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%cd C:/Users/Lakhan/Desktop/Wyng/Demand Forecasting\n",
    "from FeatureSelectionPipe import FeatureSelector\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Constant Features\n",
      "['Var2', 'Employer_Category_Food', 'Employer_Category_Retail', 'Var3', 'Employer_Category_Technology', 'Category2_F', 'Category3_2', 'Category2_G', 'City_Type_F', 'Employer_Category_Broadcasting', 'Employer_Category_Software Industry', 'Category2_C', 'Twitter_Shared', 'Employer_Category_Consulting', 'Employer_Category_Telecom', 'Category3_1', 'Online_Follower', 'Employer_Category_Real Estate', 'Facebook_Shared', 'Var4', 'Employer_Category_Education', 'Category2_B', 'Employer_Category_Transport', 'Category2_E', 'Employer_Category_Others', 'Employer_Category_BFSI', 'Employer_Category_Manufacturing', 'Category2_D', 'City_Type_I', 'Category2_A', 'Employer_Category_Health']\n",
      "\n",
      "Removing Correlated Features\n",
      "['Interaction_to_Registration', 'Interaction_to_Camp_End_Date']\n",
      "\n",
      "Removing Multicorrelated Features\n",
      "['Education_Score']\n",
      "\n",
      "Done selecting features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['City_Type_C',\n",
       " 'Age',\n",
       " 'Interaction_to_Camp_Start_Date',\n",
       " 'City_Type_E',\n",
       " 'Var1',\n",
       " 'City_Type_A',\n",
       " 'Registration_to_Camp_End_Date',\n",
       " 'City_Type_D',\n",
       " 'Income',\n",
       " 'LinkedIn_Shared',\n",
       " 'City_Type_H',\n",
       " 'Registration_to_Camp_Start_Date',\n",
       " 'City_Type_B',\n",
       " 'City_Type_NaN',\n",
       " 'Employer_Category_NaN',\n",
       " 'Var5',\n",
       " 'City_Type_G']"
      ]
     },
     "execution_count": 1415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define steps\n",
    "step1 = {'Constant Features': {'frac_constant_values': 0.95}}\n",
    "\n",
    "step2 = {'Correlated Features': {'correlation_threshold': 0.95}}\n",
    "\n",
    "step3 = {'Multicorrelated Features': {'acceptable_vif_threshold': 50}}\n",
    "\n",
    "# # For RFECV Features, DecisionTreeRegressor can also be used as an estimator\n",
    "# estimator = RandomForestClassifier(random_state = 42, n_estimators = 20) \n",
    "\n",
    "# step5 = {'RFECV Features': {'estimator': estimator,\n",
    "#                     'cv': TimeSeriesSplit(n_splits=3), \n",
    "#                     'step': 1,\n",
    "#                     'scoring': 'accuracy', \n",
    "#                     'verbose': 50}}\n",
    "\n",
    "steps = [step1, step2, step3]\n",
    "\n",
    "# Initialize FeatureSelector()\n",
    "fs = FeatureSelector()\n",
    "\n",
    "# Apply feature selection methods\n",
    "fs.fit(train_X, train_y, steps)\n",
    "\n",
    "fs.selected_features\n",
    "\n",
    "selected_features = list(set(fs.selected_features + fs.critical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1416,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_selected = fs.transform(train_X)\n",
    "test_X_selected = fs.transform(test_X)\n",
    "\n",
    "testVS = fs.transform(testVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1.0: 5207, 0.0: 3009})\n",
      "Resampled dataset shape Counter({1.0: 5207, 0.0: 5207})\n"
     ]
    }
   ],
   "source": [
    "# applying smote\n",
    "sm = SMOTE(sampling_strategy='auto',random_state=42)\n",
    "# sm = BorderlineSMOTE(sampling_strategy='auto',random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(train_X_selected, train_y)\n",
    "print('Original dataset shape %s' % Counter(train_y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# train_X_selected, train_y\n",
    "# X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The roc_auc_score of the classifier on the train set was: 68.62410017243577\n",
      "The roc_auc_score of the classifier on the test set was: 66.99737939273922\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# estimator = CatBoostClassifier(verbose=False, boosting_type=\"Plain\")\n",
    "# Initiate classifier instance\n",
    "params = {'colsample_bytree': 1, 'eta': 0.1, 'max_depth': 5, 'min_child_weight': 7, \n",
    "            'n_estimators': 50, 'objective': 'binary:logistic', 'subsample': 0.9}\n",
    "\n",
    "# estimator = Pipeline([('scaler', MinMaxScaler()), ('lr', xgb.XGBClassifier())])\n",
    "\n",
    "estimator = xgb.XGBClassifier()\n",
    "# # XGBClassifier\n",
    "# # early_stopping_rounds: The number of rounds without improvements after which we should stop\n",
    "# param_grid = { 'objective': ['binary:logistic'],\n",
    "#               'max_depth': [3,4,5,6], 'min_child_weight': [5,6,7,8],\n",
    "#               'subsample': [0.7,0.8,0.9,1], 'colsample_bytree': [0.7,0.8,0.9,1],\n",
    "# # eta parameter: https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20208\n",
    "#               'eta': [0.1,0.05], 'n_estimators': [25, 50, 100]\n",
    "#          }\n",
    "\n",
    "# param_grid = { 'scale_pos_weight': [2,]}\n",
    "\n",
    "# # Initialize GridSearch object with 5-fold cross validation\n",
    "# # error_score = 0 silences any exceptions for incorrect param combinations\n",
    "# gscv = GridSearchCV(estimator, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = 'roc_auc', error_score=0)\n",
    "\n",
    "# # Fit gscv\n",
    "# gscv = gscv.fit(train_X, train_y)\n",
    "\n",
    "# # Get best parameters and score\n",
    "# best_params = gscv.best_params_\n",
    "# best_score = gscv.best_score_\n",
    "        \n",
    "# # Update classifier parameters\n",
    "# estimator = estimator.set_params(**best_params)\n",
    "\n",
    "# Fit classifier\n",
    "estimator = estimator.fit(train_X_selected, train_y)\n",
    "\n",
    "# Make predictions\n",
    "train_y_pred = estimator.predict(train_X_selected)\n",
    "test_y_pred = estimator.predict(test_X_selected)\n",
    "\n",
    "# Measure performance\n",
    "roc_auc_score_train = roc_auc_score(train_y, train_y_pred)\n",
    "roc_auc_score_test = roc_auc_score(test_y, test_y_pred)\n",
    "\n",
    "# Message to user\n",
    "print(f'The roc_auc_score of the classifier on the train set was: {roc_auc_score_train*100}')\n",
    "print(f'The roc_auc_score of the classifier on the test set was: {roc_auc_score_test*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempVS['Outcome'] = np.round(estimator.predict_proba(testVS)[:,1], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tempHS.append(tempVS, ignore_index=True, sort=False)\n",
    "\n",
    "result.to_csv('Submissions/new_features.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Health_Camp_ID</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500633</td>\n",
       "      <td>6584</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>506945</td>\n",
       "      <td>6582</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>497447</td>\n",
       "      <td>6551</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496446</td>\n",
       "      <td>6533</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>525212</td>\n",
       "      <td>6567</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>507387</td>\n",
       "      <td>6583</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500798</td>\n",
       "      <td>6572</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>489618</td>\n",
       "      <td>6551</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>495624</td>\n",
       "      <td>6582</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>488974</td>\n",
       "      <td>6566</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>497921</td>\n",
       "      <td>6582</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>487003</td>\n",
       "      <td>6559</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>512612</td>\n",
       "      <td>6579</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>490589</td>\n",
       "      <td>6579</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>497155</td>\n",
       "      <td>6582</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>525448</td>\n",
       "      <td>6566</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>513657</td>\n",
       "      <td>6583</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>503269</td>\n",
       "      <td>6525</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>511086</td>\n",
       "      <td>6566</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>503229</td>\n",
       "      <td>6584</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>499917</td>\n",
       "      <td>6566</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>527545</td>\n",
       "      <td>6568</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>487368</td>\n",
       "      <td>6568</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>498968</td>\n",
       "      <td>6567</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>515677</td>\n",
       "      <td>6551</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>514406</td>\n",
       "      <td>6567</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>508986</td>\n",
       "      <td>6579</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>488434</td>\n",
       "      <td>6584</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>505677</td>\n",
       "      <td>6556</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>524292</td>\n",
       "      <td>6584</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35219</th>\n",
       "      <td>519398</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35220</th>\n",
       "      <td>524974</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35221</th>\n",
       "      <td>517599</td>\n",
       "      <td>6576</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35222</th>\n",
       "      <td>526937</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35223</th>\n",
       "      <td>498494</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35224</th>\n",
       "      <td>503390</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35225</th>\n",
       "      <td>512702</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35226</th>\n",
       "      <td>508325</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35227</th>\n",
       "      <td>499177</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35228</th>\n",
       "      <td>508927</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229</th>\n",
       "      <td>525504</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35230</th>\n",
       "      <td>524294</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35231</th>\n",
       "      <td>503353</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35232</th>\n",
       "      <td>516221</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35233</th>\n",
       "      <td>508014</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35234</th>\n",
       "      <td>508292</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35235</th>\n",
       "      <td>525935</td>\n",
       "      <td>6576</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35236</th>\n",
       "      <td>524472</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35237</th>\n",
       "      <td>492555</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35238</th>\n",
       "      <td>504434</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35239</th>\n",
       "      <td>508893</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35240</th>\n",
       "      <td>492477</td>\n",
       "      <td>6573</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35241</th>\n",
       "      <td>492973</td>\n",
       "      <td>6576</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35242</th>\n",
       "      <td>507203</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35243</th>\n",
       "      <td>485741</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35244</th>\n",
       "      <td>509378</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35245</th>\n",
       "      <td>500409</td>\n",
       "      <td>6548</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35246</th>\n",
       "      <td>522325</td>\n",
       "      <td>6574</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35247</th>\n",
       "      <td>524587</td>\n",
       "      <td>6574</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35248</th>\n",
       "      <td>496556</td>\n",
       "      <td>6550</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35249 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_ID  Health_Camp_ID  Outcome\n",
       "0          500633            6584    0.403\n",
       "1          506945            6582    0.112\n",
       "2          497447            6551    0.272\n",
       "3          496446            6533    0.077\n",
       "4          525212            6567    0.663\n",
       "5          507387            6583    0.729\n",
       "6          500798            6572    0.249\n",
       "7          489618            6551    0.252\n",
       "8          495624            6582    0.149\n",
       "9          488974            6566    0.111\n",
       "10         497921            6582    0.211\n",
       "11         487003            6559    0.158\n",
       "12         512612            6579    0.473\n",
       "13         490589            6579    0.233\n",
       "14         497155            6582    0.257\n",
       "15         525448            6566    0.088\n",
       "16         513657            6583    0.215\n",
       "17         503269            6525    0.240\n",
       "18         511086            6566    0.126\n",
       "19         503229            6584    0.358\n",
       "20         499917            6566    0.203\n",
       "21         527545            6568    0.063\n",
       "22         487368            6568    0.185\n",
       "23         498968            6567    0.306\n",
       "24         515677            6551    0.262\n",
       "25         514406            6567    0.372\n",
       "26         508986            6579    0.367\n",
       "27         488434            6584    0.268\n",
       "28         505677            6556    0.049\n",
       "29         524292            6584    0.277\n",
       "...           ...             ...      ...\n",
       "35219      519398            6548    0.593\n",
       "35220      524974            6548    0.743\n",
       "35221      517599            6576    0.541\n",
       "35222      526937            6548    0.521\n",
       "35223      498494            6573    0.289\n",
       "35224      503390            6573    0.315\n",
       "35225      512702            6548    0.442\n",
       "35226      508325            6573    0.460\n",
       "35227      499177            6573    0.441\n",
       "35228      508927            6550    0.700\n",
       "35229      525504            6548    0.737\n",
       "35230      524294            6548    0.790\n",
       "35231      503353            6550    0.519\n",
       "35232      516221            6573    0.491\n",
       "35233      508014            6548    0.268\n",
       "35234      508292            6548    0.824\n",
       "35235      525935            6576    0.541\n",
       "35236      524472            6550    0.488\n",
       "35237      492555            6548    0.673\n",
       "35238      504434            6550    0.701\n",
       "35239      508893            6550    0.770\n",
       "35240      492477            6573    0.617\n",
       "35241      492973            6576    0.194\n",
       "35242      507203            6550    0.367\n",
       "35243      485741            6550    0.419\n",
       "35244      509378            6548    0.792\n",
       "35245      500409            6548    0.764\n",
       "35246      522325            6574    0.694\n",
       "35247      524587            6574    0.384\n",
       "35248      496556            6550    0.682\n",
       "\n",
       "[35249 rows x 3 columns]"
      ]
     },
     "execution_count": 1421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
