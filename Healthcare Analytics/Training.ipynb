{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from boruta import BorutaPy\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from knnmv_master.impute import KNNMVImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Interm/train.csv')\n",
    "test = pd.read_csv('Interm/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = train.shape[0]\n",
    "combine = train.append(test, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_one_hot_features = ['City_Type','Employer_Category','Category2','Category3']\n",
    "target_cols = ['Target_1','Target_2']\n",
    "\n",
    "# One hot encoding\n",
    "for i in list_one_hot_features:\n",
    "    temp_one_hot = pd.get_dummies(combine[[i]], columns=[i])\n",
    "    combine = combine.join(temp_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combine.iloc[0:train_index].reset_index(drop=True)\n",
    "test = combine.iloc[train_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for camp type 1 and 2 (Favorable Outcome: Getting a health score)\n",
    "** HS: Health Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHS = train[(train['Category1'] == 'First') | (train['Category1'] == 'Second')].reset_index(drop=True)\n",
    "\n",
    "testHS = test[(test['Category1'] == 'First') | (test['Category1'] == 'Second')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainHS[set(trainHS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                + list_one_hot_features + target_cols))]\n",
    "\n",
    "y = trainHS['Target_1']\n",
    "\n",
    "tempHS = testHS[['Patient_ID','Health_Camp_ID']]\n",
    "testHS = testHS[set(testHS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                                  + list_one_hot_features))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=True) # Shuffle = True\n",
    "\n",
    "train_X = train_X.reset_index(drop=True); train_y = train_y.reset_index(drop=True);\n",
    "test_X = test_X.reset_index(drop=True); test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakhan\\Desktop\\Wyng\\Demand Forecasting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%cd C:/Users/Lakhan/Desktop/Wyng/Demand Forecasting\n",
    "from FeatureSelectionPipe import FeatureSelector\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Constant Features\n",
      "['Employer_Category_Food', 'Employer_Category_Retail', 'Var3', 'Category3_2', 'Category2_G', 'Employer_Category_Broadcasting', 'Employer_Category_Telecom', 'Category3_1', 'Employer_Category_Real Estate', 'Var4', 'Employer_Category_Education', 'Employer_Category_Transport', 'Employer_Category_BFSI', 'Employer_Category_Manufacturing', 'Employer_Category_Health']\n",
      "\n",
      "Removing Correlated Features\n",
      "[]\n",
      "\n",
      "Removing Multicorrelated Features\n",
      "['Category2_F', 'Education_Score']\n",
      "\n",
      "Done selecting features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['City_Type_C',\n",
       " 'Age',\n",
       " 'Var2',\n",
       " 'Employer_Category_Technology',\n",
       " 'City_Type_E',\n",
       " 'Var1',\n",
       " 'City_Type_A',\n",
       " 'City_Type_F',\n",
       " 'Registration_to_Camp_End_Date',\n",
       " 'City_Type_D',\n",
       " 'Employer_Category_Software Industry',\n",
       " 'Category2_C',\n",
       " 'Twitter_Shared',\n",
       " 'Employer_Category_Consulting',\n",
       " 'Online_Follower',\n",
       " 'Income',\n",
       " 'Facebook_Shared',\n",
       " 'LinkedIn_Shared',\n",
       " 'City_Type_H',\n",
       " 'Interaction_to_Registration',\n",
       " 'Registration_to_Camp_Start_Date',\n",
       " 'Category2_B',\n",
       " 'Category2_E',\n",
       " 'City_Type_B',\n",
       " 'Employer_Category_Others',\n",
       " 'Category2_D',\n",
       " 'City_Type_I',\n",
       " 'Category2_A',\n",
       " 'Var5',\n",
       " 'City_Type_G']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define steps\n",
    "step1 = {'Constant Features': {'frac_constant_values': 0.98}}\n",
    "\n",
    "step2 = {'Correlated Features': {'correlation_threshold': 0.85}}\n",
    "\n",
    "step3 = {'Multicorrelated Features': {'acceptable_vif_threshold': 15}}\n",
    "\n",
    "# # For RFECV Features, DecisionTreeRegressor can also be used as an estimator\n",
    "# estimator = RandomForestClassifier(random_state = 42, n_estimators = 20) \n",
    "\n",
    "# step5 = {'RFECV Features': {'estimator': estimator,\n",
    "#                     'cv': TimeSeriesSplit(n_splits=3), \n",
    "#                     'step': 1,\n",
    "#                     'scoring': 'accuracy', \n",
    "#                     'verbose': 50}}\n",
    "\n",
    "steps = [step1, step2, step3]\n",
    "\n",
    "# Initialize FeatureSelector()\n",
    "fs = FeatureSelector()\n",
    "\n",
    "# Apply feature selection methods\n",
    "fs.fit(train_X, train_y, steps)\n",
    "\n",
    "fs.selected_features\n",
    "\n",
    "selected_features = list(set(fs.selected_features + fs.critical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_selected = fs.transform(train_X)\n",
    "test_X_selected = fs.transform(test_X)\n",
    "\n",
    "testHS = fs.transform(testHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0.0: 40635, 1.0: 11103})\n",
      "Resampled dataset shape Counter({0.0: 40635, 1.0: 40635})\n"
     ]
    }
   ],
   "source": [
    "# applying smote\n",
    "# sm = SMOTE(sampling_strategy='auto',random_state=42)\n",
    "sm = BorderlineSMOTE(sampling_strategy='auto',random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(train_X_selected, train_y)\n",
    "print('Original dataset shape %s' % Counter(train_y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# train_X_selected, train_y\n",
    "# X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the train set was: 80.16980435585087\n",
      "The accuracy of the classifier on the test set was: 79.62891379976807\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initiate classifier instance\n",
    "estimator = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# # XGBClassifier\n",
    "# # early_stopping_rounds: The number of rounds without improvements after which we should stop\n",
    "# param_grid = { 'objective': ['binary:logistic'],\n",
    "#               'max_depth': [3,4,5,6], 'min_child_weight': [5,6,7,8],\n",
    "#               'subsample': [0.7,0.8,0.9,1], 'colsample_bytree': [0.7,0.8,0.9,1],\n",
    "# # eta parameter: https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20208\n",
    "#               'eta': [0.1,0.05], 'n_estimators': [25, 50, 100]\n",
    "#          }\n",
    "\n",
    "\n",
    "# # Initialize GridSearch object with 5-fold cross validation\n",
    "# # error_score = 0 silences any exceptions for incorrect param combinations\n",
    "# gscv = GridSearchCV(estimator, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = 'accuracy', error_score=0)\n",
    "\n",
    "# # Fit gscv\n",
    "# gscv = gscv.fit(X_res, y_res)\n",
    "\n",
    "# # Get best parameters and score\n",
    "# best_params = gscv.best_params_\n",
    "# best_score = gscv.best_score_\n",
    "        \n",
    "# # Update classifier parameters\n",
    "# estimator = estimator.set_params(**best_params)\n",
    "\n",
    "# Fit classifier\n",
    "estimator = estimator.fit(X_res, y_res)\n",
    "\n",
    "# Make predictions\n",
    "y_res_pred = estimator.predict(X_res)\n",
    "test_y_pred = estimator.predict(test_X_selected)\n",
    "\n",
    "# Measure performance\n",
    "accuracy_train = accuracy_score(y_res, y_res_pred)\n",
    "accuracy_test = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "# Message to user\n",
    "print(f'The accuracy of the classifier on the train set was: {accuracy_train*100}')\n",
    "print(f'The accuracy of the classifier on the test set was: {accuracy_test*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempHS['Outcome'] = np.round(estimator.predict_proba(testHS)[:,1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for camp type 3 (Favorable Outcome: Visiting a stall)\n",
    "** VS: Visiting a stall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVS = train[train['Category1'] == 'Third'].reset_index(drop=True)\n",
    "testVS = test[test['Category1'] == 'Third'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainVS[set(trainVS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                + list_one_hot_features + target_cols))]\n",
    "\n",
    "y = trainVS['Target_2']\n",
    "\n",
    "tempVS = testVS[['Patient_ID','Health_Camp_ID']]\n",
    "testVS = testVS[set(testVS.columns).difference(set(['Patient_ID','Health_Camp_ID','Category1'] \\\n",
    "                                                                  + list_one_hot_features))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, shuffle=True) # Shuffle = True\n",
    "\n",
    "train_X = train_X.reset_index(drop=True); train_y = train_y.reset_index(drop=True);\n",
    "test_X = test_X.reset_index(drop=True); test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lakhan\\Desktop\\Wyng\\Demand Forecasting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%cd C:/Users/Lakhan/Desktop/Wyng/Demand Forecasting\n",
    "from FeatureSelectionPipe import FeatureSelector\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Constant Features\n",
      "['Employer_Category_Food', 'Employer_Category_Retail', 'Var3', 'Category2_F', 'Category3_2', 'Category2_G', 'Employer_Category_Broadcasting', 'Category2_C', 'Employer_Category_Telecom', 'Category3_1', 'Employer_Category_Real Estate', 'Var4', 'Employer_Category_Education', 'Category2_B', 'Employer_Category_Transport', 'Category2_E', 'Employer_Category_BFSI', 'Employer_Category_Manufacturing', 'Category2_D', 'Category2_A', 'Employer_Category_Health']\n",
      "\n",
      "Removing Correlated Features\n",
      "['Registration_to_Camp_Start_Date']\n",
      "\n",
      "Removing Multicorrelated Features\n",
      "['Education_Score']\n",
      "\n",
      "Done selecting features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['City_Type_C',\n",
       " 'Age',\n",
       " 'Var2',\n",
       " 'Employer_Category_Technology',\n",
       " 'City_Type_E',\n",
       " 'Var1',\n",
       " 'City_Type_A',\n",
       " 'City_Type_F',\n",
       " 'Registration_to_Camp_End_Date',\n",
       " 'City_Type_D',\n",
       " 'Employer_Category_Software Industry',\n",
       " 'Twitter_Shared',\n",
       " 'Employer_Category_Consulting',\n",
       " 'Online_Follower',\n",
       " 'Income',\n",
       " 'Facebook_Shared',\n",
       " 'LinkedIn_Shared',\n",
       " 'City_Type_H',\n",
       " 'Interaction_to_Registration',\n",
       " 'City_Type_B',\n",
       " 'Employer_Category_Others',\n",
       " 'City_Type_I',\n",
       " 'Var5',\n",
       " 'City_Type_G']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define steps\n",
    "step1 = {'Constant Features': {'frac_constant_values': 0.98}}\n",
    "\n",
    "step2 = {'Correlated Features': {'correlation_threshold': 0.85}}\n",
    "\n",
    "step3 = {'Multicorrelated Features': {'acceptable_vif_threshold': 15}}\n",
    "\n",
    "# # For RFECV Features, DecisionTreeRegressor can also be used as an estimator\n",
    "# estimator = RandomForestClassifier(random_state = 42, n_estimators = 20) \n",
    "\n",
    "# step5 = {'RFECV Features': {'estimator': estimator,\n",
    "#                     'cv': TimeSeriesSplit(n_splits=3), \n",
    "#                     'step': 1,\n",
    "#                     'scoring': 'accuracy', \n",
    "#                     'verbose': 50}}\n",
    "\n",
    "steps = [step1, step2, step3]\n",
    "\n",
    "# Initialize FeatureSelector()\n",
    "fs = FeatureSelector()\n",
    "\n",
    "# Apply feature selection methods\n",
    "fs.fit(train_X, train_y, steps)\n",
    "\n",
    "fs.selected_features\n",
    "\n",
    "selected_features = list(set(fs.selected_features + fs.critical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_selected = fs.transform(train_X)\n",
    "test_X_selected = fs.transform(test_X)\n",
    "\n",
    "testVS = fs.transform(testVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1.0: 5233, 0.0: 2983})\n",
      "Resampled dataset shape Counter({1.0: 5233, 0.0: 5233})\n"
     ]
    }
   ],
   "source": [
    "# applying smote\n",
    "sm = SMOTE(sampling_strategy='auto',random_state=42)\n",
    "# sm = BorderlineSMOTE(sampling_strategy='auto',random_state=42)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(train_X_selected, train_y)\n",
    "print('Original dataset shape %s' % Counter(train_y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# train_X_selected, train_y\n",
    "# X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1536 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.9min\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initiate classifier instance\n",
    "\n",
    "# params = {'colsample_bytree': 0.9, 'eta': 0.1, 'max_depth': 6, 'min_child_weight': 8, \n",
    "#           'objective': 'binary:logistic', 'subsample': 1}\n",
    "\n",
    "# params = {'colsample_bytree': 0.7, 'eta': 0.1, 'max_depth': 5, 'min_child_weight': 5, \n",
    "#            'n_estimators': 50, 'objective': 'binary:logistic', 'subsample': 0.9}\n",
    "\n",
    "estimator = xgb.XGBClassifier()\n",
    "\n",
    "# XGBClassifier\n",
    "# early_stopping_rounds: The number of rounds without improvements after which we should stop\n",
    "param_grid = { 'objective': ['binary:logistic'],\n",
    "              'max_depth': [3,4,5,6], 'min_child_weight': [5,6,7,8],\n",
    "              'subsample': [0.7,0.8,0.9,1], 'colsample_bytree': [0.7,0.8,0.9,1],\n",
    "# eta parameter: https://www.kaggle.com/c/santander-customer-satisfaction/discussion/20208\n",
    "              'eta': [0.1,0.05], 'n_estimators': [25, 50, 100]\n",
    "         }\n",
    "\n",
    "\n",
    "# Initialize GridSearch object with 5-fold cross validation\n",
    "# error_score = 0 silences any exceptions for incorrect param combinations\n",
    "gscv = GridSearchCV(estimator, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = 'accuracy', error_score=0)\n",
    "\n",
    "# Fit gscv\n",
    "gscv = gscv.fit(X_res, y_res)\n",
    "\n",
    "# Get best parameters and score\n",
    "best_params = gscv.best_params_\n",
    "best_score = gscv.best_score_\n",
    "        \n",
    "# Update classifier parameters\n",
    "estimator = estimator.set_params(**best_params)\n",
    "\n",
    "# Fit classifier\n",
    "estimator = estimator.fit(X_res, y_res)\n",
    "\n",
    "# Make predictions\n",
    "y_res_pred = estimator.predict(X_res)\n",
    "test_y_pred = estimator.predict(test_X_selected)\n",
    "\n",
    "# Measure performance\n",
    "accuracy_train = accuracy_score(y_res, y_res_pred)\n",
    "accuracy_test = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "# Message to user\n",
    "print(f'The accuracy of the classifier on the train set was: {accuracy_train*100}')\n",
    "print(f'The accuracy of the classifier on the test set was: {accuracy_test*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempVS['Outcome'] = np.round(estimator.predict_proba(testVS)[:,1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tempHS.append(tempVS, ignore_index=True, sort=False)\n",
    "\n",
    "result.to_csv('V1.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
