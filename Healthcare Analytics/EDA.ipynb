{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knnmv_master.impute import KNNMVImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train/Train.csv')\n",
    "health_camps = pd.read_csv('Train/Health_Camp_Detail.csv')\n",
    "patient_profile = pd.read_csv('Train/Patient_Profile.csv')\n",
    "first = pd.read_csv('Train/First_Health_Camp_Attended.csv')\n",
    "second = pd.read_csv('Train/Second_Health_Camp_Attended.csv')\n",
    "third = pd.read_csv('Train/Third_Health_Camp_Attended.csv')\n",
    "\n",
    "test = pd.read_csv('test_l0Auv8Q.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patient Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_profile = patient_profile.replace('None', np.nan)\n",
    "\n",
    "patient_profile['First_Interaction'] = pd.to_datetime(patient_profile['First_Interaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling NaN columns, Income, Education_Score, Age, City_Type and Employer_Category\n",
    "categorical_cols = ['City_Type','Employer_Category']\n",
    "\n",
    "for i in categorical_cols:\n",
    "    patient_profile[i].fillna('NaN', inplace=True)\n",
    "    \n",
    "# for i in categorical_cols:\n",
    "#     temp_one_hot = pd.get_dummies(patient_profile[[i]], columns=[i])\n",
    "#     patient_profile = patient_profile.join(temp_one_hot)\n",
    "    \n",
    "#     patient_profile = patient_profile.drop(columns=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "# numerical columns containing NaNs (to be impuuted)\n",
    "missing_numerical_cols = ['Income', 'Education_Score', 'Age']\n",
    "\n",
    "all_numerical_cols = ['Online_Follower', 'LinkedIn_Shared', 'Twitter_Shared',\n",
    "       'Facebook_Shared', 'Income', 'Education_Score', 'Age']\n",
    "\n",
    "# all_numerical_cols = ['Online_Follower', 'LinkedIn_Shared', 'Twitter_Shared',\n",
    "#        'Facebook_Shared', 'Income', 'Education_Score', 'Age',\n",
    "#        'City_Type_A', 'City_Type_B', 'City_Type_C',\n",
    "#        'City_Type_D', 'City_Type_E', 'City_Type_F', 'City_Type_G',\n",
    "#        'City_Type_H', 'City_Type_I', 'City_Type_NaN', 'Employer_Category_BFSI',\n",
    "#        'Employer_Category_Broadcasting', 'Employer_Category_Consulting',\n",
    "#        'Employer_Category_Education', 'Employer_Category_Food',\n",
    "#        'Employer_Category_Health', 'Employer_Category_Manufacturing',\n",
    "#        'Employer_Category_NaN', 'Employer_Category_Others',\n",
    "#        'Employer_Category_Real Estate', 'Employer_Category_Retail',\n",
    "#        'Employer_Category_Software Industry', 'Employer_Category_Technology',\n",
    "#        'Employer_Category_Telecom', 'Employer_Category_Transport']\n",
    "\n",
    "for i in missing_numerical_cols:\n",
    "    patient_profile[i] = patient_profile[i].astype(float)\n",
    "#     patient_profile[i] = patient_profile.fillna(patient_profile[i].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # technique 1\n",
    "# temp = patient_profile[all_numerical_cols].iloc[0:2000]\n",
    "# # documentation: https://github.com/massibelloni-medium/knnmv\n",
    "# knnmv_imp = KNNMVImputer(strategy=\"median\", k=5, l=0.25)\n",
    "# temp = knnmv_imp.fit_transform(temp.to_numpy(), verbose=True)\n",
    "\n",
    "# technique 2\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imputer = IterativeImputer(random_state=0, max_iter=100, imputation_order='descending')\n",
    "temp = imputer.fit_transform(patient_profile[all_numerical_cols])\n",
    "\n",
    "# common for both 1 and 2\n",
    "temp = pd.DataFrame(temp, columns=all_numerical_cols)\n",
    "\n",
    "patient_profile = pd.concat([patient_profile[set(patient_profile.columns).difference(set(all_numerical_cols))],\n",
    "                                                                       temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employer_Category    0\n",
       "City_Type            0\n",
       "First_Interaction    0\n",
       "Patient_ID           0\n",
       "Online_Follower      0\n",
       "LinkedIn_Shared      0\n",
       "Twitter_Shared       0\n",
       "Facebook_Shared      0\n",
       "Income               0\n",
       "Education_Score      0\n",
       "Age                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Employer_Category            object\n",
       "City_Type                    object\n",
       "First_Interaction    datetime64[ns]\n",
       "Patient_ID                    int64\n",
       "Online_Follower             float64\n",
       "LinkedIn_Shared             float64\n",
       "Twitter_Shared              float64\n",
       "Facebook_Shared             float64\n",
       "Income                      float64\n",
       "Education_Score             float64\n",
       "Age                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_profile.isna().sum()\n",
    "patient_profile.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Health Camp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_camps['Camp_Start_Date'] = pd.to_datetime(health_camps['Camp_Start_Date'])\n",
    "health_camps['Camp_End_Date'] = pd.to_datetime(health_camps['Camp_End_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Registration_Date'] = pd.to_datetime(train['Registration_Date'])\n",
    "\n",
    "test['Registration_Date'] = pd.to_datetime(test['Registration_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75278, 8)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74944, 8)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping data points where Registration_Date is NaN\n",
    "train.shape\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74944, 8)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74944, 18)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74944, 18)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74944, 23)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "train = train.merge(patient_profile, on=['Patient_ID'], how='left')\n",
    "train.shape\n",
    "\n",
    "train.shape\n",
    "train = train.merge(health_camps, on=['Health_Camp_ID'], how='left')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35249, 8)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(35249, 18)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(35249, 18)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(35249, 23)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n",
    "test = test.merge(patient_profile, on=['Patient_ID'], how='left')\n",
    "test.shape\n",
    "\n",
    "test.shape\n",
    "test = test.merge(health_camps, on=['Health_Camp_ID'], how='left')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74944, 23)"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74944, 26)"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first['First_Favorable'] = 1\n",
    "second['Second_Favorable'] = 1\n",
    "third['Third_Favorable'] = 1\n",
    "\n",
    "train.shape\n",
    "\n",
    "train = train.merge(first[['Patient_ID','Health_Camp_ID','First_Favorable']], \n",
    "                              on=['Patient_ID','Health_Camp_ID'], how='left')\n",
    "\n",
    "train = train.merge(second[['Patient_ID','Health_Camp_ID','Second_Favorable']], \n",
    "                              on=['Patient_ID','Health_Camp_ID'], how='left')\n",
    "\n",
    "train = train.merge(third[['Patient_ID','Health_Camp_ID','Third_Favorable']], \n",
    "                              on=['Patient_ID','Health_Camp_ID'], how='left')\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validating data correctness\n",
    "# for i in ['First','Second','Third']:    \n",
    "#     train[~train[i+'_Favorable'].isnull()]['Category1'].unique()\n",
    "\n",
    "# for i in ['First','Second','Third']:    \n",
    "#     train[train['Category1'] == i]['First_Favorable'].unique()\n",
    "#     train[train['Category1'] == i]['Second_Favorable'].unique()\n",
    "#     train[train['Category1'] == i]['Third_Favorable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Interaction_to_Registration'] = (train['Registration_Date'] - train['First_Interaction']).dt.days\n",
    "train['Registration_to_Camp_Start_Date'] = (train['Camp_Start_Date'] - train['Registration_Date']).dt.days\n",
    "train['Registration_to_Camp_End_Date'] = (train['Camp_End_Date'] - train['Registration_Date']).dt.days\n",
    "train['Interaction_to_Camp_Start_Date'] = (train['Camp_Start_Date'] - train['First_Interaction']).dt.days\n",
    "train['Interaction_to_Camp_End_Date'] = (train['Camp_End_Date'] - train['First_Interaction']).dt.days\n",
    "\n",
    "\n",
    "test['Interaction_to_Registration'] = (test['Registration_Date'] - test['First_Interaction']).dt.days\n",
    "test['Registration_to_Camp_Start_Date'] = (test['Camp_Start_Date'] - test['Registration_Date']).dt.days\n",
    "test['Registration_to_Camp_End_Date'] = (test['Camp_End_Date'] - test['Registration_Date']).dt.days\n",
    "test['Interaction_to_Camp_Start_Date'] = (test['Camp_Start_Date'] - test['First_Interaction']).dt.days\n",
    "test['Interaction_to_Camp_End_Date'] = (test['Camp_End_Date'] - test['First_Interaction']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining First and Second as one classification problem and the third as another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first or second favorable\n",
    "train.loc[(train['First_Favorable'] == 1) | (train['Second_Favorable'] == 1), 'Target_1'] = 1\n",
    "train['Target_1'].fillna(0, inplace=True)\n",
    "\n",
    "# third favorable\n",
    "train['Target_2'] = train['Third_Favorable'].fillna(0)\n",
    "\n",
    "# # Solving each case separately (training 3 different models)\n",
    "# train['Target_1'] = train['First_Favorable'].fillna(0)\n",
    "# train['Target_2'] = train['Second_Favorable'].fillna(0)\n",
    "# train['Target_3'] = train['Third_Favorable'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Registration_Date','First_Interaction','Camp_Start_Date','Camp_End_Date',\n",
    "             'First_Favorable','Second_Favorable','Third_Favorable']\n",
    "\n",
    "train = train.drop(columns=drop_cols)\n",
    "\n",
    "test = test.drop(columns=['Registration_Date','First_Interaction','Camp_Start_Date','Camp_End_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding off age, income and education_score columns\n",
    "for i in missing_numerical_cols:\n",
    "    train[i] = train[i].round(0)\n",
    "    test[i] = test[i].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('Interm/train.csv', index=0)\n",
    "test.to_csv('Interm/test.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
